{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Evaluation_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am5OR1E1f08L"
      },
      "source": [
        "# **Bacterial Image Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MisCnPZgB3Z"
      },
      "source": [
        "### Libraries\n",
        "*   Scikit-Image\n",
        "> Image processing\n",
        "*   Open Source Computer Vision\n",
        "> SIFT and SURF\n",
        "*   Scikit-Learn\n",
        "> PCA\n",
        "*   Tensorflow\n",
        "> Deep learning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoVh7CDJTsRc"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import skimage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import io\n",
        "from skimage import filters as ft\n",
        "from skimage import exposure\n",
        "from skimage import util\n",
        "from skimage import feature\n",
        "from skimage.morphology import disk\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEbR7DoUiA3I"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X72gnu9tiqIc"
      },
      "source": [
        "### Display Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkpptjdLUgfI"
      },
      "source": [
        "class DisplayImages:\n",
        "    \n",
        "    def saveImage(image, name):\n",
        "        name = 'C:/Users/dell/Desktop/Enhance Image/'+name + '.tif'\n",
        "        io.imsave(name, image, plugin='tifffile')\n",
        "    \n",
        "    def showImage(image, name = 'ok'):\n",
        "        name = name + ' -> min: ' + str(np.min(image)) + ' max: ' + str(np.max(image))\n",
        "        cv2.imshow(name , image)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae5hGXdXit5F"
      },
      "source": [
        "### Dataset Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaTsi4mBUc8n"
      },
      "source": [
        "class DatasetLabels:\n",
        "\n",
        "    bacterialGenSep = ['Acinetobacter.baumanii','Actinomyces.israeli','Bacteroides.fragilis','Bifidobacterium.spp','Candida.albicans','Clostridium.perfringens','Enterococcus.faecalis','Enterococcus.faecium','Escherichia.coli','Fusobacterium']\n",
        "\n",
        "    def getLabelFromImageName(imageName):\n",
        "        imageName = imageName.replace('.tif','')  \n",
        "        imageName = imageName.split('_')\n",
        "        tempName = imageName[0]\n",
        "        for ni in imageName[1:-1]:\n",
        "            tempName += '.' + ni\n",
        "        return DatasetLabels.getIndex(tempName)\n",
        "    \n",
        "    def getIndex(imageName):\n",
        "        return DatasetLabels.bacterialGenSep.index(imageName)\n",
        "    \n",
        "    def getNameAt(index):\n",
        "        return DatasetLabels.bacterialGenSep[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9MCRl76i8he"
      },
      "source": [
        "### Read Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm3DmWa7UPwB"
      },
      "source": [
        "class ReadImage:\n",
        "\n",
        "    def readImageFrom(imagePath):\n",
        "        return cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    def getAllImagesAddress(dirPath):\n",
        "        imageNames = os.listdir(dirPath)\n",
        "        random.shuffle(imageNames)\n",
        "        return [os.path.join(dirPath, fname) for fname in imageNames], imageNames\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od8DjDNMi-Yd"
      },
      "source": [
        "### Preprocess Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRcnQglyUODt"
      },
      "source": [
        "class PreprocessImage:\n",
        "    \n",
        "    def inversOfImage(image):\n",
        "        return util.invert(np.array(image, dtype='uint8'))\n",
        "    \n",
        "    def removeNoise(image):\n",
        "        return ft.rank.median(image, skimage.morphology.disk(2))\n",
        "    \n",
        "    def rescaleIntensity(image):\n",
        "        return exposure.rescale_intensity(image, out_range='uint8')\n",
        "    \n",
        "    def enhanceEdges(image):\n",
        "        edgeExist = feature.canny(image, sigma=0.2)\n",
        "        image[edgeExist]= np.max(image)\n",
        "        return image\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B64NKeOgjD1s"
      },
      "source": [
        "### Image Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjo4W1czUI1c"
      },
      "source": [
        "class ImageFeatures:\n",
        "    \n",
        "    def siftExtractor(image):\n",
        "        sift = cv2.xfeatures2d.SIFT_create(sigma = 1.6)\n",
        "        keyPoints, descripter = sift.detectAndCompute(image, None)   \n",
        "        return descripter\n",
        "\n",
        "    def surfExtractor(image):\n",
        "        surf = cv2.xfeatures2d.SURF_create()\n",
        "        keyPoints, descripter = surf.detectAndCompute(image, None)        \n",
        "        return descripter\n",
        "\n",
        "    def reduceSiftFeatures(features):\n",
        "        pca = PCA(n_components= 35)\n",
        "        pcaComponents = np.array(pca.fit_transform(features.T))\n",
        "        return pcaComponents\n",
        "    \n",
        "    def reduceSurfFeatures(features):\n",
        "        pca = PCA(n_components= 4)\n",
        "        pcaComponents = np.array(pca.fit_transform(features.T))\n",
        "        print(pcaComponents.shape, end = ', ')\n",
        "        return pcaComponents\n",
        "    \n",
        "    def getFeatrues(imagePath, featureExtractor):\n",
        "        # Read-Image                \n",
        "        image = ReadImage.readImageFrom(imagePath)\n",
        "        \n",
        "        # Pre-Process        \n",
        "        image = PreprocessImage.inversOfImage(image)\n",
        "        image = PreprocessImage.removeNoise(image)\n",
        "        image = PreprocessImage.rescaleIntensity(image)\n",
        "        image = PreprocessImage.enhanceEdges(image)\n",
        "        \n",
        "        if featureExtractor == 'SIFT':\n",
        "            # SIFT Features\n",
        "            imageFeatures = ImageFeatures.siftExtractor(image)\n",
        "            imageFeatures = ImageFeatures.reduceSiftFeatures(imageFeatures)\n",
        "        else:\n",
        "            # SURF Features\n",
        "            imageFeatures = ImageFeatures.surfExtractor(image)\n",
        "            imageFeatures = ImageFeatures.reduceSurfFeatures(imageFeatures)\n",
        "        \n",
        "        return imageFeatures\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec-8oUcNUGo1"
      },
      "source": [
        "def getImageLabelFeatures(dirPath, featureExtractor):\n",
        "    \n",
        "    imagePaths, imageNames = ReadImage.getAllImagesAddress(dirPath)\n",
        "    \n",
        "    ImagesFeatureArray = []\n",
        "    LabelsArray = []\n",
        "    \n",
        "    for i, imagePath in enumerate(imagePaths):        \n",
        "        # Image Label\n",
        "        imageLabel = DatasetLabels.getLabelFromImageName(imageNames[i])\n",
        "        \n",
        "        #Get Image Features\n",
        "        imageFeatures = ImageFeatures.getFeatrues(imagePath, featureExtractor)\n",
        "        \n",
        "        # Add to Array\n",
        "        ImagesFeatureArray.append(imageFeatures)\n",
        "        LabelsArray.append(imageLabel)\n",
        "        \n",
        "    return ImagesFeatureArray, LabelsArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssuU_6JMT9t_"
      },
      "source": [
        "class ModelCallback(tf.keras.callbacks.Callback):   \n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        ACCURACY_THRESHOLD =  0.95\n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):\n",
        "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = ModelCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zZXlt6HjRjt"
      },
      "source": [
        "### Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZZQ6xQLT0sK"
      },
      "source": [
        "class DeepNeuralNetwork:\n",
        "\n",
        "  def trainModel(xTrain, yTrain, xTest, yTest, featureExtractor):\n",
        "\n",
        "    if featureExtractor == 'SIFT':\n",
        "        model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(128, 35)),\n",
        "            tf.keras.layers.Dense(7616, activation='relu'),\n",
        "            tf.keras.layers.Dense(3808, activation='relu'),\n",
        "            tf.keras.layers.Dense(3808, activation='relu'),\n",
        "            tf.keras.layers.Dense(1904, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005),\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "    else:\n",
        "\n",
        "        model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(64, 4)),\n",
        "            tf.keras.layers.Dense(4480, activation='relu'),\n",
        "            tf.keras.layers.Dense(2240, activation='relu'),\n",
        "            tf.keras.layers.Dense(2240, activation='relu'),\n",
        "            tf.keras.layers.Dense(1120, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005),\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "        \n",
        "    history = model.fit(xtrain, ytrain, epochs=50, batch_size= 100, verbose=1, callbacks=[callbacks])\n",
        "    model.evaluate(x_test, y_test)\n",
        "    model.save(\"F:/UNIVERSITY/SMESTER 7/FYP/Dataset/RAW/\"+featureExtractor+\"rainedModel.h5\")\n",
        "\n",
        "    DeepNeuralNetwork.plotAccuracyGraph(history)\n",
        "\n",
        "    def plotAccuracyGraph(history):\n",
        "        accuracy = history.history['accuracy']\n",
        "        loss = history.history['loss']\n",
        "        epochs = range(len(accuracy))\n",
        "        plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "        plt.title('Training Accuracy')\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vImT5fEjqMQ"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a931VoOUDI6"
      },
      "source": [
        "def Main(featureExtractor):\n",
        "\n",
        "  TrainFileDir = 'F:/UNIVERSITY/SMESTER 7/FYP/Dataset/Croped/Train'\n",
        "  xTrain, yTrain = getImageLabelFeatures(TrainFileDir, featureExtractor)\n",
        "  \n",
        "  TestFileDir = 'F:/UNIVERSITY/SMESTER 7/FYP/Dataset/Croped/Test'\n",
        "  xTest, yTest = getImageLabelFeatures(TestFileDir, featureExtractor)\n",
        "\n",
        "  DeepNeuralNetwork.trainModel(xTrain, yTrain, xTest, yTest, featureExtractor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3FJ3Mi8el57"
      },
      "source": [
        "featureExtractor = 'SIFT'\n",
        "Main(featureExtractor)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}